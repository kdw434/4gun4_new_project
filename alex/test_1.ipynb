{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afb97c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0892cf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('/Users/t2023-m0149/Documents/spartacodingclub/Projects/4. insurance/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3991f415",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv('/Users/t2023-m0149/Documents/spartacodingclub/Projects/4. insurance/sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b797a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/Users/t2023-m0149/Documents/spartacodingclub/Projects/4. insurance/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2834c2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ï†ÑÏ≤¥ Ìñâ Í∞úÏàò : 1200000\n",
      "id                           0\n",
      "Age                      18705\n",
      "Gender                       0\n",
      "Annual Income            44949\n",
      "Marital Status           18529\n",
      "Number of Dependents    109672\n",
      "Education Level              0\n",
      "Occupation              358075\n",
      "Health Score             74076\n",
      "Location                     0\n",
      "Policy Type                  0\n",
      "Previous Claims         364029\n",
      "Vehicle Age                  6\n",
      "Credit Score            137882\n",
      "Insurance Duration           1\n",
      "Policy Start Date            0\n",
      "Customer Feedback        77824\n",
      "Smoking Status               0\n",
      "Exercise Frequency           0\n",
      "Property Type                0\n",
      "Premium Amount               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Ï†ÑÏ≤¥ Ìñâ Í∞úÏàò :\", len(train))\n",
    "print(train.isna().sum())     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce64008e",
   "metadata": {},
   "source": [
    "## Îç∞Ïù¥ÌÑ∞ Ï†ÑÏ≤òÎ¶¨(ÎÇòÎ®∏ÏßÄ Î≥ÄÏàò, Í≥µÌÜµ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ed8052d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Number of Dependents\n",
    "train['Number of Dependents'] = train['Number of Dependents'].astype('Int64')\n",
    "train['Number of Dependents'] = train['Number of Dependents'].astype('category')\n",
    "train['Number of Dependents'] = train['Number of Dependents'].cat.add_categories('Missing')\n",
    "train['Number of Dependents'] = train['Number of Dependents'].fillna('Missing')\n",
    "\n",
    "\n",
    "# Age\n",
    "train['Age'] = train['Age'].fillna(train['Age'].median())\n",
    "\n",
    "\n",
    "# Annual Income\n",
    "train['Annual Income'] = train['Annual Income'].fillna(train['Annual Income'].median())\n",
    "\n",
    "\n",
    "# Health Score\n",
    "train['Health Score'] = train['Health Score'].fillna(train['Health Score'].median())\n",
    "\n",
    "\n",
    "# Credit Score\n",
    "train['Credit Score'] = train['Credit Score'].fillna('Missing')\n",
    "\n",
    "\n",
    "# Customer Feedback\n",
    "train['Customer Feedback'] = train['Customer Feedback'].fillna('No Feedback')\n",
    "\n",
    "\n",
    "# Marital Status\n",
    "train['Marital Status'] = train['Marital Status'].fillna('Unknown')\n",
    "\n",
    "\n",
    "# Vehicle Age Í≤∞Ï∏° Ìñâ ÏÇ≠Ï†ú\n",
    "train = train[train['Vehicle Age'].notnull()]\n",
    "\n",
    "\n",
    "# Insurance Duration Í≤∞Ï∏° Ìñâ ÏÇ≠Ï†ú\n",
    "train = train[train['Insurance Duration'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "645e830e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           0\n",
       "Age                          0\n",
       "Gender                       0\n",
       "Annual Income                0\n",
       "Marital Status               0\n",
       "Number of Dependents         0\n",
       "Education Level              0\n",
       "Occupation              358074\n",
       "Health Score                 0\n",
       "Location                     0\n",
       "Policy Type                  0\n",
       "Previous Claims         364028\n",
       "Vehicle Age                  0\n",
       "Credit Score                 0\n",
       "Insurance Duration           0\n",
       "Policy Start Date            0\n",
       "Customer Feedback            0\n",
       "Smoking Status               0\n",
       "Exercise Frequency           0\n",
       "Property Type                0\n",
       "Premium Amount               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab0dd32",
   "metadata": {},
   "source": [
    "### ÏÉÅÍ¥ÄÍ≥ÑÏàò"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24097c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas numpy seaborn matplotlib scipy scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60b85f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# import scipy.stats as stats\n",
    "# from sklearn.feature_selection import mutual_info_regression\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# # Ï†ÑÏ≤òÎ¶¨: Number_of_Dependents_bin ÏÉùÏÑ±\n",
    "# train['Number of Dependents'] = train['Number of Dependents'].fillna(0)\n",
    "# def bin_dependents(x):\n",
    "#    if x == 0:\n",
    "#        return '0'\n",
    "#    elif x <= 2:\n",
    "#        return '1-2'\n",
    "#    else:\n",
    "#        return '3+'\n",
    "# train['Number_of_Dependents_bin'] = train['Number of Dependents'].apply(bin_dependents)\n",
    "\n",
    "\n",
    "# # 1) ÏàòÏπòÌòï Í∞Ñ Pearson ÏÉÅÍ¥ÄÎ∂ÑÏÑù\n",
    "# num_cols = ['Age', 'Annual Income', 'Health Score', 'Vehicle Age', 'Insurance Duration']\n",
    "# corr = train[num_cols].corr(method='pearson')\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.heatmap(corr, annot=True, cmap='coolwarm', square=True)\n",
    "# plt.title('üìä Pearson Correlation: Numeric Features')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# # 2) Î≤îÏ£ºÌòï-ÏàòÏπòÌòï Î∂ÑÏÑù: Boxplot + ANOVA\n",
    "# sns.boxplot(x='Marital Status', y='Age', data=train)\n",
    "# plt.title('üéØ Age by Marital Status')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# grouped = [train.loc[train['Marital Status'] == g, 'Age'].dropna() for g in train['Marital Status'].unique()]\n",
    "# anova_result = stats.f_oneway(*grouped)\n",
    "# print('ANOVA p-value:', anova_result.pvalue)\n",
    "\n",
    "\n",
    "# # 3) Î≤îÏ£ºÌòï-Î≤îÏ£ºÌòï Î∂ÑÏÑù: Ïπ¥Ïù¥Ï†úÍ≥± + Cram√©r‚Äôs V + Countplot\n",
    "# contingency = pd.crosstab(train['Marital Status'], train['Number_of_Dependents_bin'])\n",
    "# chi2, p, dof, expected = stats.chi2_contingency(contingency)\n",
    "# print('Chi2-test p-value:', p)\n",
    "\n",
    "\n",
    "# def cramers_v(conf_matrix):\n",
    "#    chi2 = stats.chi2_contingency(conf_matrix)[0]\n",
    "#    n = conf_matrix.sum().sum()\n",
    "#    r, k = conf_matrix.shape\n",
    "#    return np.sqrt(chi2 / (n * (min(r, k)-1)))\n",
    "\n",
    "\n",
    "# print(\"Cram√©r‚Äôs V:\", cramers_v(contingency))\n",
    "\n",
    "\n",
    "# sns.countplot(data=train, x='Marital Status', hue='Number_of_Dependents_bin')\n",
    "# plt.title('üì¶ Countplot of Marital Status by Dependents Bin')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# # 4) Mutual Information Î∂ÑÏÑù (ÌòºÌï©Ìòï)\n",
    "# df_enc = train.copy()\n",
    "\n",
    "\n",
    "# # Î≤îÏ£ºÌòï Î≥ÄÏàò Ïù∏ÏΩîÎî©\n",
    "# for col in df_enc.select_dtypes(include=['object', 'category']).columns:\n",
    "#    df_enc[col] = LabelEncoder().fit_transform(df_enc[col].astype(str))\n",
    "\n",
    "\n",
    "# # YÍ∞í (target Î≥ÄÏàò) ÏÑ§Ï†ï\n",
    "# y = df_enc['Premium Amount']  # ‚Üê target Î≥ÄÏàòÎ™Ö ÌïÑÏöî Ïãú ÏàòÏ†ï\n",
    "# X = df_enc.drop(columns=['Premium Amount'])\n",
    "\n",
    "\n",
    "# # Mutual Information Í≥ÑÏÇ∞\n",
    "# mi = mutual_info_regression(X, y, discrete_features='auto')\n",
    "# mi_df = pd.DataFrame({'feature': X.columns, 'mutual_info': mi})\n",
    "# mi_df = mi_df.sort_values(by='mutual_info', ascending=False)\n",
    "\n",
    "\n",
    "# # ÏãúÍ∞ÅÌôî\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# sns.barplot(x='feature', y='mutual_info', data=mi_df)\n",
    "# plt.title('üß† Mutual Information with Target')\n",
    "# plt.xticks(rotation=90)s\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b58867d",
   "metadata": {},
   "source": [
    "# Ïã§Ìóò1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a45814c",
   "metadata": {},
   "source": [
    "1. Occupation\n",
    "- 1-1. 'unknown'ÏúºÎ°ú ÎåÄÏ≤¥\n",
    "- 1-2. Î≤îÏ£ºÎ≥Ñ annual incomeÍ∞í ÎπÑÍµêÌï¥ÏÑú ÎåÄÏ≤¥\n",
    "\n",
    "2. Previous Claims\n",
    "- 2-1. 0Í∞íÏúºÎ°ú Ï≤òÎ¶¨\n",
    "- 2-2. 0~9 Î≤îÏ£ºÌôî, nullÎ°ú ÎåÄÏ≤¥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922bd39c",
   "metadata": {},
   "source": [
    "### Ïã§Ìóò1 > 1-1 & 2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "500c122b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = train.copy()\n",
    "train1['Occupation'] = train1['Occupation'].fillna('Unknown')\n",
    "\n",
    "\n",
    "train1['Previous Claims'] = train1['Previous Claims'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c72f9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = train.copy()\n",
    "train2['Occupation'] = train2['Occupation'].fillna('Unknown')\n",
    "\n",
    "\n",
    "train2['Previous Claims'] = train2['Previous Claims'].astype('Int64')\n",
    "train2['Previous Claims'] = train2['Previous Claims'].astype('category')\n",
    "train2['Previous Claims'] = train2['Previous Claims'].cat.add_categories('Missing')\n",
    "train2['Previous Claims'] = train2['Previous Claims'].fillna('Missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c63e58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train3 = train.copy()\n",
    "occupation_income_mean = train.groupby('Occupation')['Annual Income'].mean()\n",
    "def fill_occupation(row):\n",
    "  if pd.isnull(row['Occupation']):\n",
    "      diffs = (occupation_income_mean - row['Annual Income']).abs()\n",
    "      return diffs.idxmin()\n",
    "  else:\n",
    "      return row['Occupation']\n",
    "\n",
    "\n",
    "train3['Occupation'] = train3.apply(fill_occupation, axis=1)\n",
    "\n",
    "\n",
    "train3['Previous Claims'] = train3['Previous Claims'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c288a8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train4 = train.copy()\n",
    "occupation_income_mean = train.groupby('Occupation')['Annual Income'].mean()\n",
    "def fill_occupation(row):\n",
    "  if pd.isnull(row['Occupation']):\n",
    "      diffs = (occupation_income_mean - row['Annual Income']).abs()\n",
    "      return diffs.idxmin()\n",
    "  else:\n",
    "      return row['Occupation']\n",
    "\n",
    "\n",
    "train4['Occupation'] = train4.apply(fill_occupation, axis=1)\n",
    "\n",
    "\n",
    "train4['Previous Claims'] = train4['Previous Claims'].astype('Int64')\n",
    "train4['Previous Claims'] = train4['Previous Claims'].astype('category')\n",
    "train4['Previous Claims'] = train4['Previous Claims'].cat.add_categories('Missing')\n",
    "train4['Previous Claims'] = train4['Previous Claims'].fillna('Missing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9268a2eb",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbc57b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in ./lib/python3.10/site-packages (1.2.8)\n",
      "Requirement already satisfied: pandas>=0.24 in ./lib/python3.10/site-packages (from catboost) (2.3.1)\n",
      "Requirement already satisfied: graphviz in ./lib/python3.10/site-packages (from catboost) (0.21)\n",
      "Requirement already satisfied: matplotlib in ./lib/python3.10/site-packages (from catboost) (3.10.5)\n",
      "Requirement already satisfied: scipy in ./lib/python3.10/site-packages (from catboost) (1.15.3)\n",
      "Requirement already satisfied: six in ./lib/python3.10/site-packages (from catboost) (1.17.0)\n",
      "Requirement already satisfied: plotly in ./lib/python3.10/site-packages (from catboost) (6.2.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.16.0 in ./lib/python3.10/site-packages (from catboost) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./lib/python3.10/site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./lib/python3.10/site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./lib/python3.10/site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./lib/python3.10/site-packages (from matplotlib->catboost) (4.59.0)\n",
      "Requirement already satisfied: pillow>=8 in ./lib/python3.10/site-packages (from matplotlib->catboost) (11.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./lib/python3.10/site-packages (from matplotlib->catboost) (25.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./lib/python3.10/site-packages (from matplotlib->catboost) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in ./lib/python3.10/site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./lib/python3.10/site-packages (from matplotlib->catboost) (3.2.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./lib/python3.10/site-packages (from matplotlib->catboost) (1.4.8)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in ./lib/python3.10/site-packages (from plotly->catboost) (2.0.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 25.2 is available.\n",
      "You should consider upgrading via the '/Users/t2023-m0149/Documents/GitHub/4gun4_new_project/alex/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install catboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5b1b3ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (713573081.py, line 63)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[15], line 63\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(f\"üìå R2:   {r2:.4f}\")„Ñ¥\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# 2. ÌÉÄÍ≤ü ÏÑ§Ï†ï\n",
    "target1 = 'Premium Amount'\n",
    "y1 = train1[target1]\n",
    "X1 = train1.drop(columns=[target1])\n",
    "\n",
    "\n",
    "# 3. Í≤∞Ï∏°Ïπò Ï≤òÎ¶¨ Î∞è Î≤îÏ£ºÌòï Ïª¨Îüº ÏßÄÏ†ï\n",
    "cat_features1 = X1.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "\n",
    "# NaNÏùÑ Î¨∏ÏûêÏó¥ 'Missing'ÏúºÎ°ú Î≥ÄÌôò (CatBoost Ìò∏Ìôò)\n",
    "for col in cat_features1:\n",
    "   X1[col] = X1[col].astype(str).fillna(\"Missing\")\n",
    "\n",
    "\n",
    "# Ïà´ÏûêÌòï Ïª¨Îüº NaNÏùÄ Ï§ëÏïôÍ∞íÏúºÎ°ú ÎåÄÏ≤¥\n",
    "for col in X1.select_dtypes(include=[np.number]).columns:\n",
    "   if X1[col].isnull().sum() > 0:\n",
    "       X1[col] = X1[col].fillna(X1[col].median())\n",
    "\n",
    "\n",
    "# 4. ÌïôÏäµ/Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞ Î∂ÑÎ¶¨\n",
    "X_train1, X_val1, y_train1, y_val1 = train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# 5. Î™®Îç∏ Ï†ïÏùò\n",
    "model1 = CatBoostRegressor(\n",
    "   iterations=1000,\n",
    "   learning_rate=0.05,\n",
    "   depth=6,\n",
    "   eval_metric='MAE',\n",
    "   cat_features=cat_features1,\n",
    "   random_seed=42,\n",
    "   verbose=100\n",
    ")\n",
    "\n",
    "\n",
    "# 6. Î™®Îç∏ ÌïôÏäµ\n",
    "model1.fit(X_train1, y_train1, eval_set=(X_val1, y_val1), use_best_model=True)\n",
    "\n",
    "\n",
    "# 7. ÏòàÏ∏° Î∞è ÌèâÍ∞Ä\n",
    "y_pred1 = model1.predict(X_val1)\n",
    "\n",
    "\n",
    "# Îã§ÏñëÌïú ÌèâÍ∞ÄÏßÄÌëú Ï∂úÎ†•\n",
    "mae = mean_absolute_error(y_val1, y_pred1)\n",
    "mse = mean_squared_error(y_val1, y_pred1)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_val1, y_pred1)\n",
    "\n",
    "\n",
    "print(f\"üìå MAE:  {mae:.4f}\")\n",
    "print(f\"üìå MSE:  {mse:.4f}\")\n",
    "print(f\"üìå RMSE: {rmse:.4f}\")\n",
    "print(f\"üìå R2:   {r2:.4f}\")„Ñ¥\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed6bf61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Features: ['Gender', 'Marital Status', 'Number of Dependents', 'Education Level', 'Occupation', 'Location', 'Policy Type', 'Previous Claims', 'Credit Score', 'Policy Start Date', 'Customer Feedback', 'Smoking Status', 'Exercise Frequency', 'Property Type']\n",
      "Gender                  object\n",
      "Marital Status          object\n",
      "Number of Dependents    object\n",
      "Education Level         object\n",
      "Occupation              object\n",
      "Location                object\n",
      "Policy Type             object\n",
      "Previous Claims         object\n",
      "Credit Score            object\n",
      "Policy Start Date       object\n",
      "Customer Feedback       object\n",
      "Smoking Status          object\n",
      "Exercise Frequency      object\n",
      "Property Type           object\n",
      "dtype: object\n",
      "0:\tlearn: 667.9957958\ttest: 668.7504018\tbest: 668.7504018 (0)\ttotal: 1.27s\tremaining: 21m 10s\n",
      "100:\tlearn: 653.7569083\ttest: 654.0719997\tbest: 654.0719997 (100)\ttotal: 5m 39s\tremaining: 50m 24s\n",
      "200:\tlearn: 650.4555579\ttest: 650.7101920\tbest: 650.7101920 (200)\ttotal: 14m 32s\tremaining: 57m 49s\n",
      "300:\tlearn: 648.5507692\ttest: 648.7653519\tbest: 648.7653519 (300)\ttotal: 25m 2s\tremaining: 58m 10s\n",
      "400:\tlearn: 646.8784779\ttest: 647.0883025\tbest: 647.0764638 (398)\ttotal: 30m 5s\tremaining: 44m 56s\n",
      "500:\tlearn: 645.9964941\ttest: 646.2142727\tbest: 646.2127673 (496)\ttotal: 34m 19s\tremaining: 34m 11s\n",
      "600:\tlearn: 645.5947060\ttest: 645.9210703\tbest: 645.9114401 (584)\ttotal: 38m 59s\tremaining: 25m 53s\n",
      "700:\tlearn: 645.1294000\ttest: 645.5306877\tbest: 645.5276143 (693)\ttotal: 43m 14s\tremaining: 18m 26s\n",
      "800:\tlearn: 644.8586762\ttest: 645.3606559\tbest: 645.3532022 (789)\ttotal: 47m 41s\tremaining: 11m 50s\n",
      "900:\tlearn: 644.4804676\ttest: 645.0836087\tbest: 645.0824615 (897)\ttotal: 52m 2s\tremaining: 5m 43s\n",
      "999:\tlearn: 644.2272453\ttest: 644.9377799\tbest: 644.9242033 (984)\ttotal: 56m 7s\tremaining: 0us\n",
      "\n",
      "bestTest = 644.9242033\n",
      "bestIteration = 984\n",
      "\n",
      "Shrink model to first 985 iterations.\n",
      "train2 MAE:  644.9242\n",
      "train2 MSE:  717054.2292\n",
      "train2 RMSE: 846.7905\n",
      "train2 R2:   0.0460\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "target2 = 'Premium Amount'\n",
    "y2 = train2[target2]\n",
    "X2 = train2.drop(columns=[target2])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Ïò¨Î∞îÎ•∏ cat_features Ï∂îÏ∂ú (train2 Í∏∞Ï§Ä)\n",
    "cat_features2 = X2.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Î≤îÏ£ºÌòï Í≤∞Ï∏° Î¨∏Ïûê 'Missing' ÎåÄÏ≤¥\n",
    "for col in cat_features2:\n",
    "  X2[col] = X2[col].astype(str).fillna('Missing')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ÏàòÏπòÌòï Í≤∞Ï∏°ÏùÄ Ï§ëÏïôÍ∞í ÎåÄÏ≤¥\n",
    "for col in X2.select_dtypes(include=[np.number]).columns:\n",
    "  if X2[col].isnull().sum() > 0:\n",
    "      X2[col] = X2[col].fillna(X2[col].median())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# cat_features Î¶¨Ïä§Ìä∏ÏôÄ Ïã§Ï†ú Ïª¨Îüº ÌÉÄÏûÖ ÌôïÏù∏\n",
    "print(\"Categorical Features:\", cat_features2)\n",
    "print(X2.dtypes[cat_features2])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ÌïôÏäµ/Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞ Î∂ÑÌï†\n",
    "X_train2, X_val2, y_train2, y_val2 = train_test_split(X2, y2, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Î™®Îç∏ Ï†ïÏùò\n",
    "model2 = CatBoostRegressor(\n",
    "  iterations=1000,\n",
    "  learning_rate=0.05,\n",
    "  depth=6,\n",
    "  eval_metric='MAE',\n",
    "  cat_features=cat_features2,\n",
    "  random_seed=42,\n",
    "  verbose=100\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Î™®Îç∏ ÌïôÏäµ\n",
    "model2.fit(X_train2, y_train2, eval_set=(X_val2, y_val2), use_best_model=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ÏòàÏ∏° Î∞è ÌèâÍ∞Ä\n",
    "y_pred2 = model2.predict(X_val2)\n",
    "mae = mean_absolute_error(y_val2, y_pred2)\n",
    "mse = mean_squared_error(y_val2, y_pred2)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_val2, y_pred2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"train2 MAE:  {mae:.4f}\")\n",
    "print(f\"train2 MSE:  {mse:.4f}\")\n",
    "print(f\"train2 RMSE: {rmse:.4f}\")\n",
    "print(f\"train2 R2:   {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03eba8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 667.9864127\ttest: 668.7337461\tbest: 668.7337461 (0)\ttotal: 2.22s\tremaining: 36m 55s\n",
      "100:\tlearn: 653.4596191\ttest: 654.0788837\tbest: 654.0788837 (100)\ttotal: 3m 37s\tremaining: 32m 12s\n",
      "200:\tlearn: 650.3516463\ttest: 650.8452309\tbest: 650.8452309 (200)\ttotal: 6m 36s\tremaining: 26m 16s\n",
      "300:\tlearn: 647.9209334\ttest: 648.2849533\tbest: 648.2849533 (300)\ttotal: 8m 42s\tremaining: 20m 13s\n",
      "400:\tlearn: 646.5360110\ttest: 647.0060495\tbest: 647.0060495 (400)\ttotal: 9m 58s\tremaining: 14m 53s\n",
      "500:\tlearn: 645.8194568\ttest: 646.3612762\tbest: 646.3612762 (500)\ttotal: 11m 13s\tremaining: 11m 10s\n",
      "600:\tlearn: 645.0868405\ttest: 645.7117993\tbest: 645.7101199 (589)\ttotal: 12m 25s\tremaining: 8m 15s\n",
      "700:\tlearn: 644.6423115\ttest: 645.3490746\tbest: 645.3449007 (695)\ttotal: 13m 41s\tremaining: 5m 50s\n",
      "800:\tlearn: 644.0361328\ttest: 644.8465411\tbest: 644.8465373 (788)\ttotal: 14m 55s\tremaining: 3m 42s\n",
      "900:\tlearn: 643.7255767\ttest: 644.6738483\tbest: 644.6655824 (885)\ttotal: 16m 7s\tremaining: 1m 46s\n",
      "999:\tlearn: 643.4967469\ttest: 644.5595860\tbest: 644.5585330 (998)\ttotal: 17m 24s\tremaining: 0us\n",
      "\n",
      "bestTest = 644.558533\n",
      "bestIteration = 998\n",
      "\n",
      "Shrink model to first 999 iterations.\n",
      "train3 MAE:  644.5585\n",
      "train3 MSE:  716538.3725\n",
      "train3 RMSE: 846.4859\n",
      "train3 R2:   0.0467\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2. ÌÉÄÍ≤ü ÏÑ§Ï†ï\n",
    "target3 = 'Premium Amount'\n",
    "y3 = train3[target3]\n",
    "X3 = train3.drop(columns=[target3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 3. Í≤∞Ï∏°Ïπò Ï≤òÎ¶¨ Î∞è Î≤îÏ£ºÌòï Ïª¨Îüº ÏßÄÏ†ï\n",
    "cat_features3 = X3.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# NaNÏùÑ Î¨∏ÏûêÏó¥ 'Missing'ÏúºÎ°ú Î≥ÄÌôò (CatBoost Ìò∏Ìôò)\n",
    "for col in cat_features3:\n",
    "  X3[col] = X3[col].astype(str).fillna(\"Missing\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Ïà´ÏûêÌòï Ïª¨Îüº NaNÏùÄ Ï§ëÏïôÍ∞íÏúºÎ°ú ÎåÄÏ≤¥\n",
    "for col in X3.select_dtypes(include=[np.number]).columns:\n",
    "  if X3[col].isnull().sum() > 0:\n",
    "      X3[col] = X3[col].fillna(X3[col].median())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 4. ÌïôÏäµ/Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞ Î∂ÑÎ¶¨\n",
    "X_train3, X_val3, y_train3, y_val3 = train_test_split(X3, y3, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 5. Î™®Îç∏ Ï†ïÏùò\n",
    "model3 = CatBoostRegressor(\n",
    "  iterations=1000,\n",
    "  learning_rate=0.05,\n",
    "  depth=6,\n",
    "  eval_metric='MAE',\n",
    "  cat_features=cat_features3,\n",
    "  random_seed=42,\n",
    "  verbose=100\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 6. Î™®Îç∏ ÌïôÏäµ\n",
    "model3.fit(X_train3, y_train3, eval_set=(X_val3, y_val3), use_best_model=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ÏòàÏ∏° Î∞è ÌèâÍ∞Ä\n",
    "y_pred3 = model3.predict(X_val3)\n",
    "mae = mean_absolute_error(y_val3, y_pred3)\n",
    "mse = mean_squared_error(y_val3, y_pred3)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_val2, y_pred3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"train3 MAE:  {mae:.4f}\")\n",
    "print(f\"train3 MSE:  {mse:.4f}\")\n",
    "print(f\"train3 RMSE: {rmse:.4f}\")\n",
    "print(f\"train3 R2:   {r2:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410cc2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 667.9957958\ttest: 668.7504018\tbest: 668.7504018 (0)\ttotal: 693ms\tremaining: 11m 31s\n",
      "100:\tlearn: 654.1391893\ttest: 654.4613850\tbest: 654.4613850 (100)\ttotal: 1m 14s\tremaining: 11m\n",
      "200:\tlearn: 650.1962425\ttest: 650.3591072\tbest: 650.3591072 (200)\ttotal: 6m 10s\tremaining: 24m 34s\n",
      "300:\tlearn: 648.1702904\ttest: 648.2604486\tbest: 648.2604486 (300)\ttotal: 11m 7s\tremaining: 25m 49s\n",
      "400:\tlearn: 646.6817101\ttest: 646.8220760\tbest: 646.8220760 (400)\ttotal: 15m 56s\tremaining: 23m 48s\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# 2. ÌÉÄÍ≤ü ÏÑ§Ï†ï\n",
    "target4 = 'Premium Amount'\n",
    "y4 = train4[target4]\n",
    "X4 = train4.drop(columns=[target4])\n",
    "\n",
    "\n",
    "# 3. Í≤∞Ï∏°Ïπò Ï≤òÎ¶¨ Î∞è Î≤îÏ£ºÌòï Ïª¨Îüº ÏßÄÏ†ï\n",
    "cat_features4 = X4.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "\n",
    "# NaNÏùÑ Î¨∏ÏûêÏó¥ 'Missing'ÏúºÎ°ú Î≥ÄÌôò (CatBoost Ìò∏Ìôò)\n",
    "for col in cat_features4:\n",
    "   X4[col] = X4[col].astype(str).fillna(\"Missing\")\n",
    "\n",
    "\n",
    "# Ïà´ÏûêÌòï Ïª¨Îüº NaNÏùÄ Ï§ëÏïôÍ∞íÏúºÎ°ú ÎåÄÏ≤¥\n",
    "for col in X4.select_dtypes(include=[np.number]).columns:\n",
    "   if X4[col].isnull().sum() > 0:\n",
    "       X4[col] = X4[col].fillna(X4[col].median())\n",
    "\n",
    "\n",
    "# 4. ÌïôÏäµ/Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞ Î∂ÑÎ¶¨\n",
    "X_train4, X_val4, y_train4, y_val4 = train_test_split(X4, y4, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# 5. Î™®Îç∏ Ï†ïÏùò\n",
    "model4 = CatBoostRegressor(\n",
    "   iterations=1000,\n",
    "   learning_rate=0.05,\n",
    "   depth=6,\n",
    "   eval_metric='MAE',\n",
    "   cat_features=cat_features4,\n",
    "   random_seed=42,\n",
    "   verbose=100\n",
    ")\n",
    "\n",
    "\n",
    "# 6. Î™®Îç∏ ÌïôÏäµ\n",
    "model4.fit(X_train4, y_train4, eval_set=(X_val4, y_val4), use_best_model=True)\n",
    "\n",
    "\n",
    "# ÏòàÏ∏° Î∞è ÌèâÍ∞Ä\n",
    "y_pred4 = model3.predict(X_val4)\n",
    "mae = mean_absolute_error(y_val4, y_pred4)\n",
    "mse = mean_squared_error(y_val4, y_pred4)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_val4, y_pred4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"train4 MAE:  {mae:.4f}\")\n",
    "print(f\"train4 MSE:  {mse:.4f}\")\n",
    "print(f\"train4 RMSE: {rmse:.4f}\")\n",
    "print(f\"train4 R2:   {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362d4c00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
